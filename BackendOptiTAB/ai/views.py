import os
import openai
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from django.conf import settings
from curriculum.models import MatiereContexte, Chapitre, Exercice
from cours.models import Cours
from .models import AIConversation
from .serializers import AIQuerySerializer, AIConversationSerializer


class AIHelper:
    """Classe utilitaire pour g√©rer les interactions avec l'IA"""

    def __init__(self):
        openai.api_key = getattr(settings, 'OPENAI_API_KEY', os.getenv('OPENAI_API_KEY'))
        if not openai.api_key:
            raise ValueError("OPENAI_API_KEY non configur√©e")

    def search_relevant_content(self, matiere_contexte=None, chapitre=None, query=""):
        """Recherche du contenu pertinent dans la base de donn√©es"""
        context_data = {
            'exercices': [],
            'cours': [],
            'chapitres': []
        }

        # Recherche par chapitre sp√©cifique
        if chapitre:
            exercices = Exercice.objects.filter(chapitre=chapitre)[:5]  # Limiter √† 5 exercices
            cours = Cours.objects.filter(chapitre=chapitre).first()

            context_data['exercices'] = [
                {
                    'titre': ex.titre,
                    'question': ex.question,
                    'reponse_correcte': ex.reponse_correcte,
                    'etapes': ex.etapes or ""
                } for ex in exercices
            ]

            if cours:
                context_data['cours'] = {
                    'titre': cours.chapitre.titre,
                    'contenu': cours.contenu if hasattr(cours, 'contenu') else "",
                    'video_url': cours.video_url or ""
                }

        # Recherche par mati√®re/contexte
        elif matiere_contexte:
            chapitres = Chapitre.objects.filter(
                notion__theme__contexte=matiere_contexte
            ).select_related('notion__theme')[:3]  # Limiter √† 3 chapitres

            for chap in chapitres:
                exercices = Exercice.objects.filter(chapitre=chap)[:3]
                context_data['exercices'].extend([
                    {
                        'chapitre': chap.titre,
                        'titre': ex.titre,
                        'question': ex.question,
                        'reponse_correcte': ex.reponse_correcte,
                        'etapes': ex.etapes or ""
                    } for ex in exercices
                ])

        return context_data

    def build_prompt(self, user_query, context_data):
        """Construit le prompt pour ChatGPT"""
        system_prompt = """Tu es un assistant p√©dagogique intelligent pour la plateforme OptiTAB.
Tu aides les √©l√®ves dans leurs apprentissages scolaires en te basant sur le contenu disponible dans la base de donn√©es.

INSTRUCTIONS IMPORTANTES:
1. R√©ponds toujours en fran√ßais
2. Sois p√©dagogique et encourageant
3. Utilise le contenu fourni pour √©tayer tes r√©ponses
4. Si tu n'as pas assez d'informations, dis-le clairement
5. Propose des exercices suppl√©mentaires si pertinent
6. Explique les concepts de mani√®re claire et progressive

CONTEXTE DISPONIBLE:
"""

        # Ajouter les exercices au prompt
        if context_data['exercices']:
            system_prompt += "\nEXERCICES DISPONIBLES:\n"
            for i, ex in enumerate(context_data['exercices'], 1):
                system_prompt += f"\n{i}. {ex['titre']}\n"
                system_prompt += f"   Question: {ex['question']}\n"
                system_prompt += f"   Solution: {ex['reponse_correcte']}\n"
                if ex.get('etapes'):
                    system_prompt += f"   √âtapes: {ex['etapes']}\n"

        # Ajouter les cours au prompt
        if context_data['cours']:
            system_prompt += f"\nCOURS DISPONIBLE:\n{context_data['cours']['contenu']}\n"

        return system_prompt

    def get_ai_response(self, user_query, context_data, model='gpt-3.5-turbo'):
        """Obtient la r√©ponse de l'IA"""
        system_prompt = self.build_prompt(user_query, context_data)

        try:
            # Nettoyer les variables d'environnement proxy probl√©matiques
            import os
            proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'OPENAI_PROXY']
            for var in proxy_vars:
                os.environ.pop(var, None)

            print("Variables proxy nettoy√©es")

            # Utilisation de l'ancienne API OpenAI v0.28.1 (compatible proxy)
            print("Utilisation de l'ancienne API OpenAI v0.28.1")

            # Configurer la cl√© API
            api_key = getattr(settings, 'OPENAI_API_KEY', os.getenv('OPENAI_API_KEY'))
            if not api_key:
                raise ValueError("OPENAI_API_KEY non configur√©e. Ajoutez-la dans vos variables d'environnement.")

            print("Cl√© API trouv√©e, configuration OpenAI...")
            openai.api_key = api_key

            response = openai.ChatCompletion.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_query}
                ],
                max_tokens=1000,
                temperature=0.7
            )

            ai_response = response.choices[0].message.content
            tokens_used = response.usage.total_tokens

            return ai_response, tokens_used

        except Exception as e:
            error_msg = str(e)
            print(f"Erreur OpenAI: {error_msg}")

            # Gestion sp√©cifique de l'erreur de quota
            if "exceeded your current quota" in error_msg.lower():
                return """üö® Cr√©dits OpenAI √©puis√©s

Votre quota OpenAI est d√©pass√©. Voici les solutions :

1Ô∏è‚É£ **Ajouter des cr√©dits** :
   ‚Ä¢ Allez sur https://platform.openai.com/account/billing
   ‚Ä¢ Cliquez sur "Add to credit balance"
   ‚Ä¢ Ajoutez au minimum 5$

2Ô∏è‚É£ **Utiliser GPT-3.5-turbo** :
   ‚Ä¢ Plus √©conomique que GPT-4
   ‚Ä¢ Suffisant pour l'√©ducation

3Ô∏è‚É£ **Attendre la remise √† z√©ro** :
   ‚Ä¢ Les cr√©dits gratuits se renouvellent le 1er du mois

üí° Conseil : Commencez par ajouter 5$ pour continuer imm√©diatement !

üìä Estimation des co√ªts :
‚Ä¢ Question simple : ~0.001$
‚Ä¢ Explication d√©taill√©e : ~0.004$
‚Ä¢ GPT-3.5-turbo : 10x moins cher que GPT-4""", 0

            return f"Erreur lors de la g√©n√©ration de la r√©ponse: {error_msg}", 0


@api_view(['POST'])
@permission_classes([IsAuthenticated])
def ask_ai(request):
    """Endpoint pour poser une question √† l'IA"""
    serializer = AIQuerySerializer(data=request.data)
    if not serializer.is_valid():
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    try:
        ai_helper = AIHelper()
    except ValueError as e:
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    # R√©cup√©rer le contexte
    matiere_contexte = None
    chapitre = None

    if serializer.validated_data.get('matiere_contexte_id'):
        try:
            matiere_contexte = MatiereContexte.objects.get(
                id=serializer.validated_data['matiere_contexte_id']
            )
        except MatiereContexte.DoesNotExist:
            return Response({'error': 'Contexte mati√®re non trouv√©'}, status=status.HTTP_404_NOT_FOUND)

    if serializer.validated_data.get('chapitre_id'):
        try:
            chapitre = Chapitre.objects.get(id=serializer.validated_data['chapitre_id'])
        except Chapitre.DoesNotExist:
            return Response({'error': 'Chapitre non trouv√©'}, status=status.HTTP_404_NOT_FOUND)

    # Rechercher le contenu pertinent
    context_data = ai_helper.search_relevant_content(
        matiere_contexte=matiere_contexte,
        chapitre=chapitre,
        query=serializer.validated_data['message']
    )

    # Obtenir la r√©ponse de l'IA
    model = serializer.validated_data.get('model', 'gpt-3.5-turbo')
    ai_response, tokens_used = ai_helper.get_ai_response(
        serializer.validated_data['message'],
        context_data,
        model
    )

    # Sauvegarder la conversation
    conversation = AIConversation.objects.create(
        user=request.user,
        message=serializer.validated_data['message'],
        ai_response=ai_response,
        contexte_matiere=matiere_contexte,
        contexte_chapitre=chapitre,
        tokens_used=tokens_used,
        model_used=model
    )

    # Retourner la r√©ponse
    response_serializer = AIConversationSerializer(conversation)
    return Response(response_serializer.data, status=status.HTTP_201_CREATED)


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def get_conversation_history(request):
    """R√©cup√®re l'historique des conversations de l'utilisateur"""
    conversations = AIConversation.objects.filter(user=request.user)
    serializer = AIConversationSerializer(conversations, many=True)
    return Response(serializer.data)